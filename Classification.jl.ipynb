{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifiers on Multiple UCI Datasets #"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Make sure these packages are added before running code ##\n",
    "\n",
    "Pkg.add(\"ScikitLearn\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"LinearAlgebra\")\n",
    "Pkg.add(\"PyCall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cars.data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>buying</th><th>maint</th><th>doors</th><th>persons</th><th>lug_boot</th><th>safety</th><th>classification</th></tr><tr><th></th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th></tr></thead><tbody><p>1,728 rows × 7 columns</p><tr><th>1</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>2</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>3</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>4</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>med</td><td>low</td><td>unacc</td></tr><tr><th>5</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>med</td><td>med</td><td>unacc</td></tr><tr><th>6</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>med</td><td>high</td><td>unacc</td></tr><tr><th>7</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>low</td><td>unacc</td></tr><tr><th>8</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>med</td><td>unacc</td></tr><tr><th>9</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>high</td><td>unacc</td></tr><tr><th>10</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>11</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>12</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>13</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>med</td><td>low</td><td>unacc</td></tr><tr><th>14</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>med</td><td>med</td><td>unacc</td></tr><tr><th>15</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>med</td><td>high</td><td>unacc</td></tr><tr><th>16</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>big</td><td>low</td><td>unacc</td></tr><tr><th>17</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>big</td><td>med</td><td>unacc</td></tr><tr><th>18</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>big</td><td>high</td><td>unacc</td></tr><tr><th>19</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>20</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>21</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>22</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>med</td><td>low</td><td>unacc</td></tr><tr><th>23</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>med</td><td>med</td><td>unacc</td></tr><tr><th>24</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>med</td><td>high</td><td>unacc</td></tr><tr><th>25</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>big</td><td>low</td><td>unacc</td></tr><tr><th>26</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>big</td><td>med</td><td>unacc</td></tr><tr><th>27</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>big</td><td>high</td><td>unacc</td></tr><tr><th>28</th><td>vhigh</td><td>vhigh</td><td>3</td><td>2</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>29</th><td>vhigh</td><td>vhigh</td><td>3</td><td>2</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>30</th><td>vhigh</td><td>vhigh</td><td>3</td><td>2</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& buying & maint & doors & persons & lug\\_boot & safety & classification\\\\\n",
       "\t\\hline\n",
       "\t& String & String & String & String & String & String & String\\\\\n",
       "\t\\hline\n",
       "\t1 & vhigh & vhigh & 2 & 2 & small & low & unacc \\\\\n",
       "\t2 & vhigh & vhigh & 2 & 2 & small & med & unacc \\\\\n",
       "\t3 & vhigh & vhigh & 2 & 2 & small & high & unacc \\\\\n",
       "\t4 & vhigh & vhigh & 2 & 2 & med & low & unacc \\\\\n",
       "\t5 & vhigh & vhigh & 2 & 2 & med & med & unacc \\\\\n",
       "\t6 & vhigh & vhigh & 2 & 2 & med & high & unacc \\\\\n",
       "\t7 & vhigh & vhigh & 2 & 2 & big & low & unacc \\\\\n",
       "\t8 & vhigh & vhigh & 2 & 2 & big & med & unacc \\\\\n",
       "\t9 & vhigh & vhigh & 2 & 2 & big & high & unacc \\\\\n",
       "\t10 & vhigh & vhigh & 2 & 4 & small & low & unacc \\\\\n",
       "\t11 & vhigh & vhigh & 2 & 4 & small & med & unacc \\\\\n",
       "\t12 & vhigh & vhigh & 2 & 4 & small & high & unacc \\\\\n",
       "\t13 & vhigh & vhigh & 2 & 4 & med & low & unacc \\\\\n",
       "\t14 & vhigh & vhigh & 2 & 4 & med & med & unacc \\\\\n",
       "\t15 & vhigh & vhigh & 2 & 4 & med & high & unacc \\\\\n",
       "\t16 & vhigh & vhigh & 2 & 4 & big & low & unacc \\\\\n",
       "\t17 & vhigh & vhigh & 2 & 4 & big & med & unacc \\\\\n",
       "\t18 & vhigh & vhigh & 2 & 4 & big & high & unacc \\\\\n",
       "\t19 & vhigh & vhigh & 2 & more & small & low & unacc \\\\\n",
       "\t20 & vhigh & vhigh & 2 & more & small & med & unacc \\\\\n",
       "\t21 & vhigh & vhigh & 2 & more & small & high & unacc \\\\\n",
       "\t22 & vhigh & vhigh & 2 & more & med & low & unacc \\\\\n",
       "\t23 & vhigh & vhigh & 2 & more & med & med & unacc \\\\\n",
       "\t24 & vhigh & vhigh & 2 & more & med & high & unacc \\\\\n",
       "\t25 & vhigh & vhigh & 2 & more & big & low & unacc \\\\\n",
       "\t26 & vhigh & vhigh & 2 & more & big & med & unacc \\\\\n",
       "\t27 & vhigh & vhigh & 2 & more & big & high & unacc \\\\\n",
       "\t28 & vhigh & vhigh & 3 & 2 & small & low & unacc \\\\\n",
       "\t29 & vhigh & vhigh & 3 & 2 & small & med & unacc \\\\\n",
       "\t30 & vhigh & vhigh & 3 & 2 & small & high & unacc \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1728×7 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m buying \u001b[0m\u001b[1m maint  \u001b[0m\u001b[1m doors  \u001b[0m\u001b[1m persons \u001b[0m\u001b[1m lug_boot \u001b[0m\u001b[1m safety \u001b[0m\u001b[1m classification \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m String \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m String   \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String         \u001b[0m\n",
       "──────┼───────────────────────────────────────────────────────────────────\n",
       "    1 │ vhigh   vhigh   2       2        small     low     unacc\n",
       "    2 │ vhigh   vhigh   2       2        small     med     unacc\n",
       "    3 │ vhigh   vhigh   2       2        small     high    unacc\n",
       "    4 │ vhigh   vhigh   2       2        med       low     unacc\n",
       "    5 │ vhigh   vhigh   2       2        med       med     unacc\n",
       "    6 │ vhigh   vhigh   2       2        med       high    unacc\n",
       "    7 │ vhigh   vhigh   2       2        big       low     unacc\n",
       "    8 │ vhigh   vhigh   2       2        big       med     unacc\n",
       "    9 │ vhigh   vhigh   2       2        big       high    unacc\n",
       "   10 │ vhigh   vhigh   2       4        small     low     unacc\n",
       "   11 │ vhigh   vhigh   2       4        small     med     unacc\n",
       "  ⋮   │   ⋮       ⋮       ⋮        ⋮        ⋮        ⋮           ⋮\n",
       " 1719 │ low     low     5more   4        big       high    vgood\n",
       " 1720 │ low     low     5more   more     small     low     unacc\n",
       " 1721 │ low     low     5more   more     small     med     acc\n",
       " 1722 │ low     low     5more   more     small     high    good\n",
       " 1723 │ low     low     5more   more     med       low     unacc\n",
       " 1724 │ low     low     5more   more     med       med     good\n",
       " 1725 │ low     low     5more   more     med       high    vgood\n",
       " 1726 │ low     low     5more   more     big       low     unacc\n",
       " 1727 │ low     low     5more   more     big       med     good\n",
       " 1728 │ low     low     5more   more     big       high    vgood\n",
       "\u001b[36m                                                         1707 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the data from all the required datasets using csv.read (store csv file containing datasets)\n",
    "using CSV, DataFrames\n",
    "\n",
    "dfCar = CSV.read(\"car.data\", DataFrame, header=0)\n",
    "\n",
    "cols = [\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\", \"classification\"]\n",
    "is_cat = [true,true,false,false,true,true,true]\n",
    "is_cat_x = is_cat[1:6]\n",
    "rename!(dfCar,cols)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant LabelEncoder. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1728-element Array{Int64,1}:\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 2\n",
       " 1\n",
       " 3\n",
       " 2\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 3\n",
       " 2\n",
       " 1\n",
       " 3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorical data for Bayes encode via label encoder,\n",
    "\n",
    "using ScikitLearn\n",
    "#first, replace 5more with 5, more with 5 in doors, persons (respectively)\n",
    "\n",
    "dfCar[!,\"doors\"][dfCar[!,\"doors\"] .== \"5more\"] .= \"5\"\n",
    "dfCar[!,\"persons\"][dfCar[!,\"persons\"] .== \"more\"] .= \"5\"\n",
    "\n",
    "#dfCar\n",
    "\n",
    "@sk_import preprocessing: LabelEncoder\n",
    "\n",
    "#label encoder for categorical columns, could potentially use OHE \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#X[:,3]\n",
    "#dfCar[!,1]\n",
    "#if categorical, \n",
    "for i in 1:7\n",
    "    if(is_cat[i] == true)\n",
    "        dfCar[!,i] = label_encoder.fit_transform(dfCar[!,i])\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "X = Array(dfCar[:,1:6]) #feature matrix\n",
    "y = Array(dfCar[:,7]) #labels \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test partition for cars ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Array,1}:\n",
       " Any[0 1 … 2 2; 0 0 … 0 1; … ; 1 2 … 2 0; 2 0 … 2 0]\n",
       " Any[1 2 … 2 2; 0 0 … 1 1; … ; 3 3 … 1 2; 1 3 … 1 0]\n",
       " [2, 2, 2, 2, 2, 2, 2, 2, 2, 2  …  1, 2, 1, 2, 0, 0, 2, 0, 1, 0]\n",
       " [0, 2, 2, 0, 2, 3, 2, 2, 2, 2  …  2, 2, 2, 2, 2, 2, 0, 3, 2, 0]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ScikitLearn\n",
    "\n",
    "using ScikitLearn.CrossValidation: train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3) #70/30 split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Classifier for Cars ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.014328 seconds (16.95 k allocations: 265.344 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.8684863523573201\n",
      "Accuracy on Test Data: \n",
      "0.8805394990366089\n",
      "  0.004388 seconds (7.30 k allocations: 119.141 KiB)\n",
      "Size of model: \n",
      "2955 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant GaussianNB. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import naive_bayes: GaussianNB\n",
    "@sk_import naive_bayes: CategoricalNB\n",
    "@sk_import metrics: accuracy_score\n",
    "using PyCall\n",
    "@pyimport joblib as jl\n",
    "gnb = CategoricalNB()\n",
    "\n",
    "@time fit!(gnb, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(gnb,X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println(score(gnb,X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time gnb.predict(X_test)\n",
    "\n",
    "\n",
    "jl.dump(gnb,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#slightly underfitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees for Cars ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.007899 seconds (16.95 k allocations: 265.344 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.8610421836228288\n",
      "Accuracy on Test Data: \n",
      "0.8535645472061657\n",
      "  0.003618 seconds (7.30 k allocations: 119.141 KiB)\n",
      "Size of model: \n",
      "3381 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant DecisionTreeClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import tree: DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "@time fit!(dt, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(dt, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(dt, X_test, y_test))\n",
    "\n",
    "\n",
    "#time to test model on test data\n",
    "@time dt.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "jl.dump(dt,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n",
    "\n",
    "\n",
    "\n",
    "#slightly overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for Cars ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.075393 seconds (16.95 k allocations: 265.344 KiB)\n",
      "Accuracy on Training Data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant SVC. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9660876757650951\n",
      "Accuracy on Test Data: \n",
      "0.928709055876686\n",
      "  0.045793 seconds (7.30 k allocations: 119.141 KiB)\n",
      "Size of model: \n",
      "86512 bytes\n"
     ]
    }
   ],
   "source": [
    "@sk_import svm: SVC\n",
    "\n",
    "svc = SVC(gamma=0.5, C=0.5)\n",
    "@time fit!(svc, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(svc, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(svc, X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time svc.predict(X_test)\n",
    "\n",
    "jl.dump(svc,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n",
    "\n",
    "#slightly overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks for Cars ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.229638 seconds (16.95 k allocations: 265.344 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.9511993382961125\n",
      "Accuracy on Test Data: \n",
      "0.9344894026974951\n",
      "  0.007012 seconds (7.30 k allocations: 119.141 KiB)\n",
      "Size of model: \n",
      "48969 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant MLPClassifier. This may fail, cause incorrect answers, or produce other errors.\n",
      "C:\\Users\\darkr\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\r\n",
      "  return f(*args, **kwargs)\r\n",
      "C:\\Users\\darkr\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\r\n",
      "  return f(*args, **kwargs)\r\n",
      "C:\\Users\\darkr\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\r\n",
      "  return f(*args, **kwargs)\r\n"
     ]
    }
   ],
   "source": [
    "@sk_import neural_network: MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=600)\n",
    "@time fit!(clf, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(clf, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(clf, X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time clf.predict(X_test)\n",
    "\n",
    "jl.dump(clf,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load abalone.data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sex</th><th>length</th><th>diameter</th><th>height</th><th>whole weight</th><th>shucked weight</th><th>viscera weight</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>4,177 rows × 9 columns (omitted printing of 2 columns)</p><tr><th>1</th><td>M</td><td>0.455</td><td>0.365</td><td>0.095</td><td>0.514</td><td>0.2245</td><td>0.101</td></tr><tr><th>2</th><td>M</td><td>0.35</td><td>0.265</td><td>0.09</td><td>0.2255</td><td>0.0995</td><td>0.0485</td></tr><tr><th>3</th><td>F</td><td>0.53</td><td>0.42</td><td>0.135</td><td>0.677</td><td>0.2565</td><td>0.1415</td></tr><tr><th>4</th><td>M</td><td>0.44</td><td>0.365</td><td>0.125</td><td>0.516</td><td>0.2155</td><td>0.114</td></tr><tr><th>5</th><td>I</td><td>0.33</td><td>0.255</td><td>0.08</td><td>0.205</td><td>0.0895</td><td>0.0395</td></tr><tr><th>6</th><td>I</td><td>0.425</td><td>0.3</td><td>0.095</td><td>0.3515</td><td>0.141</td><td>0.0775</td></tr><tr><th>7</th><td>F</td><td>0.53</td><td>0.415</td><td>0.15</td><td>0.7775</td><td>0.237</td><td>0.1415</td></tr><tr><th>8</th><td>F</td><td>0.545</td><td>0.425</td><td>0.125</td><td>0.768</td><td>0.294</td><td>0.1495</td></tr><tr><th>9</th><td>M</td><td>0.475</td><td>0.37</td><td>0.125</td><td>0.5095</td><td>0.2165</td><td>0.1125</td></tr><tr><th>10</th><td>F</td><td>0.55</td><td>0.44</td><td>0.15</td><td>0.8945</td><td>0.3145</td><td>0.151</td></tr><tr><th>11</th><td>F</td><td>0.525</td><td>0.38</td><td>0.14</td><td>0.6065</td><td>0.194</td><td>0.1475</td></tr><tr><th>12</th><td>M</td><td>0.43</td><td>0.35</td><td>0.11</td><td>0.406</td><td>0.1675</td><td>0.081</td></tr><tr><th>13</th><td>M</td><td>0.49</td><td>0.38</td><td>0.135</td><td>0.5415</td><td>0.2175</td><td>0.095</td></tr><tr><th>14</th><td>F</td><td>0.535</td><td>0.405</td><td>0.145</td><td>0.6845</td><td>0.2725</td><td>0.171</td></tr><tr><th>15</th><td>F</td><td>0.47</td><td>0.355</td><td>0.1</td><td>0.4755</td><td>0.1675</td><td>0.0805</td></tr><tr><th>16</th><td>M</td><td>0.5</td><td>0.4</td><td>0.13</td><td>0.6645</td><td>0.258</td><td>0.133</td></tr><tr><th>17</th><td>I</td><td>0.355</td><td>0.28</td><td>0.085</td><td>0.2905</td><td>0.095</td><td>0.0395</td></tr><tr><th>18</th><td>F</td><td>0.44</td><td>0.34</td><td>0.1</td><td>0.451</td><td>0.188</td><td>0.087</td></tr><tr><th>19</th><td>M</td><td>0.365</td><td>0.295</td><td>0.08</td><td>0.2555</td><td>0.097</td><td>0.043</td></tr><tr><th>20</th><td>M</td><td>0.45</td><td>0.32</td><td>0.1</td><td>0.381</td><td>0.1705</td><td>0.075</td></tr><tr><th>21</th><td>M</td><td>0.355</td><td>0.28</td><td>0.095</td><td>0.2455</td><td>0.0955</td><td>0.062</td></tr><tr><th>22</th><td>I</td><td>0.38</td><td>0.275</td><td>0.1</td><td>0.2255</td><td>0.08</td><td>0.049</td></tr><tr><th>23</th><td>F</td><td>0.565</td><td>0.44</td><td>0.155</td><td>0.9395</td><td>0.4275</td><td>0.214</td></tr><tr><th>24</th><td>F</td><td>0.55</td><td>0.415</td><td>0.135</td><td>0.7635</td><td>0.318</td><td>0.21</td></tr><tr><th>25</th><td>F</td><td>0.615</td><td>0.48</td><td>0.165</td><td>1.1615</td><td>0.513</td><td>0.301</td></tr><tr><th>26</th><td>F</td><td>0.56</td><td>0.44</td><td>0.14</td><td>0.9285</td><td>0.3825</td><td>0.188</td></tr><tr><th>27</th><td>F</td><td>0.58</td><td>0.45</td><td>0.185</td><td>0.9955</td><td>0.3945</td><td>0.272</td></tr><tr><th>28</th><td>M</td><td>0.59</td><td>0.445</td><td>0.14</td><td>0.931</td><td>0.356</td><td>0.234</td></tr><tr><th>29</th><td>M</td><td>0.605</td><td>0.475</td><td>0.18</td><td>0.9365</td><td>0.394</td><td>0.219</td></tr><tr><th>30</th><td>M</td><td>0.575</td><td>0.425</td><td>0.14</td><td>0.8635</td><td>0.393</td><td>0.227</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& sex & length & diameter & height & whole weight & shucked weight & viscera weight & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & M & 0.455 & 0.365 & 0.095 & 0.514 & 0.2245 & 0.101 & $\\dots$ \\\\\n",
       "\t2 & M & 0.35 & 0.265 & 0.09 & 0.2255 & 0.0995 & 0.0485 & $\\dots$ \\\\\n",
       "\t3 & F & 0.53 & 0.42 & 0.135 & 0.677 & 0.2565 & 0.1415 & $\\dots$ \\\\\n",
       "\t4 & M & 0.44 & 0.365 & 0.125 & 0.516 & 0.2155 & 0.114 & $\\dots$ \\\\\n",
       "\t5 & I & 0.33 & 0.255 & 0.08 & 0.205 & 0.0895 & 0.0395 & $\\dots$ \\\\\n",
       "\t6 & I & 0.425 & 0.3 & 0.095 & 0.3515 & 0.141 & 0.0775 & $\\dots$ \\\\\n",
       "\t7 & F & 0.53 & 0.415 & 0.15 & 0.7775 & 0.237 & 0.1415 & $\\dots$ \\\\\n",
       "\t8 & F & 0.545 & 0.425 & 0.125 & 0.768 & 0.294 & 0.1495 & $\\dots$ \\\\\n",
       "\t9 & M & 0.475 & 0.37 & 0.125 & 0.5095 & 0.2165 & 0.1125 & $\\dots$ \\\\\n",
       "\t10 & F & 0.55 & 0.44 & 0.15 & 0.8945 & 0.3145 & 0.151 & $\\dots$ \\\\\n",
       "\t11 & F & 0.525 & 0.38 & 0.14 & 0.6065 & 0.194 & 0.1475 & $\\dots$ \\\\\n",
       "\t12 & M & 0.43 & 0.35 & 0.11 & 0.406 & 0.1675 & 0.081 & $\\dots$ \\\\\n",
       "\t13 & M & 0.49 & 0.38 & 0.135 & 0.5415 & 0.2175 & 0.095 & $\\dots$ \\\\\n",
       "\t14 & F & 0.535 & 0.405 & 0.145 & 0.6845 & 0.2725 & 0.171 & $\\dots$ \\\\\n",
       "\t15 & F & 0.47 & 0.355 & 0.1 & 0.4755 & 0.1675 & 0.0805 & $\\dots$ \\\\\n",
       "\t16 & M & 0.5 & 0.4 & 0.13 & 0.6645 & 0.258 & 0.133 & $\\dots$ \\\\\n",
       "\t17 & I & 0.355 & 0.28 & 0.085 & 0.2905 & 0.095 & 0.0395 & $\\dots$ \\\\\n",
       "\t18 & F & 0.44 & 0.34 & 0.1 & 0.451 & 0.188 & 0.087 & $\\dots$ \\\\\n",
       "\t19 & M & 0.365 & 0.295 & 0.08 & 0.2555 & 0.097 & 0.043 & $\\dots$ \\\\\n",
       "\t20 & M & 0.45 & 0.32 & 0.1 & 0.381 & 0.1705 & 0.075 & $\\dots$ \\\\\n",
       "\t21 & M & 0.355 & 0.28 & 0.095 & 0.2455 & 0.0955 & 0.062 & $\\dots$ \\\\\n",
       "\t22 & I & 0.38 & 0.275 & 0.1 & 0.2255 & 0.08 & 0.049 & $\\dots$ \\\\\n",
       "\t23 & F & 0.565 & 0.44 & 0.155 & 0.9395 & 0.4275 & 0.214 & $\\dots$ \\\\\n",
       "\t24 & F & 0.55 & 0.415 & 0.135 & 0.7635 & 0.318 & 0.21 & $\\dots$ \\\\\n",
       "\t25 & F & 0.615 & 0.48 & 0.165 & 1.1615 & 0.513 & 0.301 & $\\dots$ \\\\\n",
       "\t26 & F & 0.56 & 0.44 & 0.14 & 0.9285 & 0.3825 & 0.188 & $\\dots$ \\\\\n",
       "\t27 & F & 0.58 & 0.45 & 0.185 & 0.9955 & 0.3945 & 0.272 & $\\dots$ \\\\\n",
       "\t28 & M & 0.59 & 0.445 & 0.14 & 0.931 & 0.356 & 0.234 & $\\dots$ \\\\\n",
       "\t29 & M & 0.605 & 0.475 & 0.18 & 0.9365 & 0.394 & 0.219 & $\\dots$ \\\\\n",
       "\t30 & M & 0.575 & 0.425 & 0.14 & 0.8635 & 0.393 & 0.227 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4177×9 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m sex    \u001b[0m\u001b[1m length  \u001b[0m\u001b[1m diameter \u001b[0m\u001b[1m height  \u001b[0m\u001b[1m whole weight \u001b[0m\u001b[1m shucked weight \u001b[0m\u001b[1m visc\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m String \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64        \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ M         0.455     0.365    0.095        0.514           0.2245       ⋯\n",
       "    2 │ M         0.35      0.265    0.09         0.2255          0.0995\n",
       "    3 │ F         0.53      0.42     0.135        0.677           0.2565\n",
       "    4 │ M         0.44      0.365    0.125        0.516           0.2155\n",
       "    5 │ I         0.33      0.255    0.08         0.205           0.0895       ⋯\n",
       "    6 │ I         0.425     0.3      0.095        0.3515          0.141\n",
       "    7 │ F         0.53      0.415    0.15         0.7775          0.237\n",
       "    8 │ F         0.545     0.425    0.125        0.768           0.294\n",
       "    9 │ M         0.475     0.37     0.125        0.5095          0.2165       ⋯\n",
       "   10 │ F         0.55      0.44     0.15         0.8945          0.3145\n",
       "   11 │ F         0.525     0.38     0.14         0.6065          0.194\n",
       "  ⋮   │   ⋮        ⋮        ⋮         ⋮          ⋮              ⋮              ⋱\n",
       " 4168 │ M         0.5       0.38     0.125        0.577           0.269\n",
       " 4169 │ F         0.515     0.4      0.125        0.615           0.2865       ⋯\n",
       " 4170 │ M         0.52      0.385    0.165        0.791           0.375\n",
       " 4171 │ M         0.55      0.43     0.13         0.8395          0.3155\n",
       " 4172 │ M         0.56      0.43     0.155        0.8675          0.4\n",
       " 4173 │ F         0.565     0.45     0.165        0.887           0.37         ⋯\n",
       " 4174 │ M         0.59      0.44     0.135        0.966           0.439\n",
       " 4175 │ M         0.6       0.475    0.205        1.176           0.5255\n",
       " 4176 │ F         0.625     0.485    0.15         1.0945          0.531\n",
       " 4177 │ M         0.71      0.555    0.195        1.9485          0.9455       ⋯\n",
       "\u001b[36m                                                 3 columns and 4156 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the data from all the required datasets using csv.read (store csv file containing datasets)\n",
    "\n",
    "dfAb = CSV.read(\"abalone.data\", DataFrame, header=0)\n",
    "\n",
    "#column titles\n",
    "cols = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\", \"shucked weight\", \n",
    "    \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "rename!(dfAb,cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing for Abalone ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant OneHotEncoder. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant LabelEncoder. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant ColumnTransformer. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4177-element Array{Int64,1}:\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting rings, want to normalize\n",
    "#no missing values, want to encode sex \n",
    "#onehot encode only sex\n",
    "@sk_import preprocessing:OneHotEncoder\n",
    "@sk_import preprocessing:LabelEncoder\n",
    "@sk_import compose:ColumnTransformer\n",
    "\n",
    "#split age into 3 classes (1-8, 9-10, 11-29)\n",
    "for i in 1:size(dfAb,1)\n",
    "    if(dfAb[i,9]<=8 && dfAb[i,9]>=1)\n",
    "        dfAb[i,9] = 1\n",
    "    elseif (dfAb[i,9]<=10 && dfAb[i,9]>=9)\n",
    "        dfAb[i,9] = 2\n",
    "    elseif (dfAb[i,9]<=29 && dfAb[i,9]>=11)\n",
    "        dfAb[i,9] = 3\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "columnTransformer = ColumnTransformer([(\"encoder\", \n",
    "                                        OneHotEncoder(), \n",
    "                                        [0])], \n",
    "                                      remainder=\"passthrough\") \n",
    "\n",
    "X = Array(dfAb[:,Not(9)])\n",
    "y = Array(dfAb[:,9])\n",
    "#print(y)\n",
    "\n",
    "X[:,1] = le.fit_transform(X[:,1])\n",
    "\n",
    "#enc = OneHotEncoder(categories=[\"sex\"],sparse=false)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test split for Abalone ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Array,1}:\n",
       " Real[2 0.535 … 0.1595 0.2155; 0 0.585 … 0.2325 0.358; … ; 2 0.625 … 0.2045 0.25; 0 0.595 … 0.1905 0.289]\n",
       " Real[1 0.5 … 0.116 0.17; 1 0.56 … 0.209 0.275; … ; 0 0.635 … 0.292 0.35; 1 0.55 … 0.1495 0.221]\n",
       " [1, 3, 2, 3, 2, 1, 1, 1, 1, 2  …  1, 1, 3, 1, 1, 3, 2, 2, 1, 2]\n",
       " [2, 3, 3, 3, 2, 1, 3, 3, 1, 3  …  3, 2, 1, 3, 1, 1, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "#train test split -> exists in python but is it in julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier for Abalone ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.012722 seconds (52.63 k allocations: 822.969 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.5805679096818337\n",
      "Accuracy on Test Data: \n",
      "0.5877192982456141\n",
      "  0.005464 seconds (22.61 k allocations: 364.047 KiB)\n",
      "Size of model: \n",
      "1101 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant CategoricalNB. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import naive_bayes: GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "@time fit!(gnb, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(gnb,X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println(score(gnb,X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time gnb.predict(X_test)\n",
    "\n",
    "jl.dump(gnb,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier for Abalone ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.016884 seconds (52.63 k allocations: 822.969 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.667464933287718\n",
      "Accuracy on Test Data: \n",
      "0.6291866028708134\n",
      "  0.005089 seconds (22.61 k allocations: 364.047 KiB)\n",
      "Size of model: \n",
      "6053 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant DecisionTreeClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import tree: DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "@time fit!(dt, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(dt, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(dt, X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time dt.predict(X_test)\n",
    "\n",
    "jl.dump(dt,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier for Abalone ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.334587 seconds (52.63 k allocations: 822.969 KiB)\n",
      "Accuracy on Training Data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant SVC. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.630516592541909\n",
      "Accuracy on Test Data: \n",
      "0.6275917065390749\n",
      "  0.263678 seconds (22.61 k allocations: 364.047 KiB)\n",
      "Size of model: \n",
      "222837 bytes\n"
     ]
    }
   ],
   "source": [
    "@sk_import svm: SVC\n",
    "\n",
    "svc = SVC(gamma=0.5, C=1)\n",
    "@time fit!(svc, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(svc, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println(score( svc, X_test, y_test))\n",
    "\n",
    "\n",
    "#time to test model on test data\n",
    "@time svc.predict(X_test)\n",
    "\n",
    "jl.dump(svc,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Abalone ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.639389 seconds (52.63 k allocations: 822.969 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.6616489907629148\n",
      "Accuracy on Test Data: \n",
      "0.6722488038277512\n",
      "  0.007193 seconds (22.61 k allocations: 364.047 KiB)\n",
      "Size of model: \n",
      "48074 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant MLPClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import neural_network: MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=700)\n",
    "@time fit!(clf, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(clf, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println(score(clf, X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time clf.predict(X_test)\n",
    "\n",
    "jl.dump(clf,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Madelon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Column1</th></tr><tr><th></th><th>Int64</th></tr></thead><tbody><p>600 rows × 1 columns</p><tr><th>1</th><td>-1</td></tr><tr><th>2</th><td>-1</td></tr><tr><th>3</th><td>-1</td></tr><tr><th>4</th><td>1</td></tr><tr><th>5</th><td>-1</td></tr><tr><th>6</th><td>1</td></tr><tr><th>7</th><td>-1</td></tr><tr><th>8</th><td>-1</td></tr><tr><th>9</th><td>-1</td></tr><tr><th>10</th><td>1</td></tr><tr><th>11</th><td>1</td></tr><tr><th>12</th><td>1</td></tr><tr><th>13</th><td>-1</td></tr><tr><th>14</th><td>1</td></tr><tr><th>15</th><td>1</td></tr><tr><th>16</th><td>-1</td></tr><tr><th>17</th><td>-1</td></tr><tr><th>18</th><td>1</td></tr><tr><th>19</th><td>-1</td></tr><tr><th>20</th><td>-1</td></tr><tr><th>21</th><td>-1</td></tr><tr><th>22</th><td>-1</td></tr><tr><th>23</th><td>-1</td></tr><tr><th>24</th><td>1</td></tr><tr><th>25</th><td>1</td></tr><tr><th>26</th><td>1</td></tr><tr><th>27</th><td>1</td></tr><tr><th>28</th><td>-1</td></tr><tr><th>29</th><td>-1</td></tr><tr><th>30</th><td>-1</td></tr><tr><th>&vellip;</th><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& Column1\\\\\n",
       "\t\\hline\n",
       "\t& Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & -1 \\\\\n",
       "\t2 & -1 \\\\\n",
       "\t3 & -1 \\\\\n",
       "\t4 & 1 \\\\\n",
       "\t5 & -1 \\\\\n",
       "\t6 & 1 \\\\\n",
       "\t7 & -1 \\\\\n",
       "\t8 & -1 \\\\\n",
       "\t9 & -1 \\\\\n",
       "\t10 & 1 \\\\\n",
       "\t11 & 1 \\\\\n",
       "\t12 & 1 \\\\\n",
       "\t13 & -1 \\\\\n",
       "\t14 & 1 \\\\\n",
       "\t15 & 1 \\\\\n",
       "\t16 & -1 \\\\\n",
       "\t17 & -1 \\\\\n",
       "\t18 & 1 \\\\\n",
       "\t19 & -1 \\\\\n",
       "\t20 & -1 \\\\\n",
       "\t21 & -1 \\\\\n",
       "\t22 & -1 \\\\\n",
       "\t23 & -1 \\\\\n",
       "\t24 & 1 \\\\\n",
       "\t25 & 1 \\\\\n",
       "\t26 & 1 \\\\\n",
       "\t27 & 1 \\\\\n",
       "\t28 & -1 \\\\\n",
       "\t29 & -1 \\\\\n",
       "\t30 & -1 \\\\\n",
       "\t$\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m600×1 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Column1 \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64   \u001b[0m\n",
       "─────┼─────────\n",
       "   1 │      -1\n",
       "   2 │      -1\n",
       "   3 │      -1\n",
       "   4 │       1\n",
       "   5 │      -1\n",
       "   6 │       1\n",
       "   7 │      -1\n",
       "   8 │      -1\n",
       "   9 │      -1\n",
       "  10 │       1\n",
       "  11 │       1\n",
       "  ⋮  │    ⋮\n",
       " 591 │      -1\n",
       " 592 │       1\n",
       " 593 │      -1\n",
       " 594 │      -1\n",
       " 595 │       1\n",
       " 596 │       1\n",
       " 597 │       1\n",
       " 598 │       1\n",
       " 599 │       1\n",
       " 600 │      -1\n",
       "\u001b[36m579 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No need for train test split, data given as test, train and validation\n",
    "trainDF = CSV.read(\"madelon_train.data\", DataFrame, header=0)\n",
    "testDF = CSV.read(\"madelon_test.data\", DataFrame, header=0)\n",
    "valDF = CSV.read(\"madelon_valid.data\", DataFrame, header=0)\n",
    "\n",
    "train_labels = CSV.read(\"madelon_train.labels\", DataFrame, header=0)\n",
    "val_labels = CSV.read(\"madelon_valid.labels\", DataFrame, header=0)\n",
    "\n",
    "#use val as test, test_y not given\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing for Madelon ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600×500 Array{Float64,2}:\n",
       " 0.00180331  0.00169503  0.00191531  …  0.00185931  0.00195265  0.00190411\n",
       " 0.00181077  0.00189665  0.00184064     0.00184811  0.00204599  0.00178091\n",
       " 0.00180331  0.00194518  0.00189291     0.0017361   0.00189665  0.00187798\n",
       " 0.00176971  0.00188171  0.00215053     0.00174357  0.00206092  0.00193025\n",
       " 0.00184811  0.00176971  0.00195265     0.00184064  0.00188918  0.00183318\n",
       " 0.00176971  0.00189291  0.00188171  …  0.00172117  0.00198625  0.00194145\n",
       " 0.00179584  0.00177344  0.00190038     0.0017361   0.00184438  0.00193772\n",
       " 0.00181451  0.00166143  0.0016577      0.00176971  0.00166517  0.00179584\n",
       " 0.00179957  0.00180331  0.00196012     0.00182944  0.00177717  0.00173984\n",
       " 0.00181824  0.00184438  0.00185931     0.00179211  0.00188545  0.00197505\n",
       " 0.00179584  0.00191531  0.00191531  …  0.00182197  0.00189665  0.00174357\n",
       " 0.00179211  0.00181824  0.00191531     0.00184064  0.00193772  0.00194892\n",
       " 0.00175477  0.00162783  0.00168757     0.00176597  0.00182571  0.00178091\n",
       " ⋮                                   ⋱                          \n",
       " 0.00179957  0.00159049  0.00178091     0.00185184  0.00198625  0.00191158\n",
       " 0.00178464  0.00187424  0.00169503     0.00181824  0.00195265  0.00188171\n",
       " 0.00179584  0.00170623  0.00189291  …  0.00184811  0.00198998  0.00168383\n",
       " 0.00181451  0.00190038  0.00158303     0.00179211  0.00193398  0.00163903\n",
       " 0.00179957  0.0017137   0.00209079     0.00194145  0.00191158  0.00167263\n",
       " 0.00177344  0.00182944  0.0023036      0.00185558  0.00200119  0.00159423\n",
       " 0.00176224  0.00174357  0.00180704     0.00184811  0.00200865  0.00183691\n",
       " 0.00184064  0.00170997  0.00187798  …  0.00182571  0.00188918  0.00188918\n",
       " 0.00179584  0.00180704  0.00179584     0.00182944  0.00169877  0.00168383\n",
       " 0.00181077  0.00181077  0.00197878     0.00179584  0.00180704  0.00193025\n",
       " 0.00178091  0.00175104  0.00197132     0.00182944  0.00228867  0.00183691\n",
       " 0.00179957  0.0016913   0.00192278     0.00184438  0.00200119  0.00196385"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have label vector (binary classification)\n",
    "#have feature matrix (need to remove last row of missings, we have labels already)\n",
    "X_train = Array(select(trainDF, Not(:Column501)))\n",
    "y_train = Array(train_labels[:,1])\n",
    "#print(X_train)\n",
    "X_test = Array(select(valDF, Not(:Column501)))\n",
    "y_test = Array(val_labels[:,1])\n",
    "\n",
    "#normalizing doesnt actually make a difference, performance remains the same (all\n",
    "#features are weighted equally)\n",
    "# we do norm here but dont actually use it - difference is negligible\n",
    "using LinearAlgebra\n",
    "X_train_norm=normalize(X_train)\n",
    "X_test_norm=normalize(X_test)\n",
    "#min max normalize features???\n",
    "# using StatsBase\n",
    "# X_train_norm = StatsBase.fit(ZScoreTransform, X_train)\n",
    "# StatsBase.transform(X_train_norm, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier for Madelon ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.014216 seconds (22 allocations: 1.125 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.714\n",
      "Accuracy on Testing Data: \n",
      "0.5916666666666667\n",
      "  0.004627 seconds (36 allocations: 6.500 KiB)\n",
      "Size of model: \n",
      "16696 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant GaussianNB. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import naive_bayes: GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "@time fit!(gnb, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(gnb,X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Testing Data: \")\n",
    "println( score(gnb,X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time gnb.predict(X_test)\n",
    "\n",
    "jl.dump(gnb,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier for Madelon ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.081047 seconds (22 allocations: 1.125 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.651\n",
      "Accuracy on Test Data: \n",
      "0.665\n",
      "  0.000923 seconds (36 allocations: 6.500 KiB)\n",
      "Size of model: \n",
      "1673 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant DecisionTreeClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import tree: DecisionTreeClassifier\n",
    "\n",
    "#limit depth to lower overfitting of tree (prune)\n",
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "@time fit!(dt, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(dt, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(dt, X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time dt.predict(X_test)\n",
    "\n",
    "\n",
    "jl.dump(dt,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier for Madelon ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.905345 seconds (22 allocations: 1.125 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.56\n",
      "Accuracy on Test Data: \n",
      "0.5183333333333333\n",
      "  0.000988 seconds (36 allocations: 6.500 KiB)\n",
      "Size of model: \n",
      "4745 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant LinearSVC. This may fail, cause incorrect answers, or produce other errors.\n",
      "C:\\Users\\darkr\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\r\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\r\n"
     ]
    }
   ],
   "source": [
    "@sk_import svm: LinearSVC\n",
    "\n",
    "svc = LinearSVC(max_iter=3000)\n",
    "@time fit!(svc, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(svc, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(svc, X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time svc.predict(X_test)\n",
    "\n",
    "jl.dump(svc,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier for Madelon ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.115958 seconds (22 allocations: 1.125 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.547\n",
      "Accuracy on Test Data: \n",
      "0.565\n",
      "  0.002618 seconds (36 allocations: 6.500 KiB)\n",
      "Size of model: \n",
      "1612019 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant MLPClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import neural_network: MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=500)\n",
    "@time fit!(clf, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(clf, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(clf, X_test, y_test))\n",
    "\n",
    "#time to test model on test data\n",
    "@time clf.predict(X_test)\n",
    "\n",
    "jl.dump(clf,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading KDD Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 2. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 3. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 4. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 5. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 6. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 7. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 8. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 9. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 10. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 11. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 12. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 13. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 14. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 15. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 16. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 17. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 18. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 19. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 20. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 21. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 22. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 23. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 24. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 25. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 26. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 27. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 28. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 29. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 30. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 31. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 32. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 33. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 34. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 35. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 36. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 37. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 38. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 39. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 40. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 41. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n",
      "┌ Warning: thread = 1 warning: only found 1 / 23 columns around data row: 42. Filling remaining columns with `missing`\n",
      "└ @ CSV C:\\Users\\darkr\\.julia\\packages\\CSV\\YUbbG\\src\\file.jl:603\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>back</th><th>buffer_overflow</th><th>ftp_write</th><th>guess_passwd</th><th>imap</th></tr><tr><th></th><th>String</th><th>Missing</th><th>Missing</th><th>Missing</th><th>Missing</th></tr></thead><tbody><p>41 rows × 23 columns (omitted printing of 18 columns)</p><tr><th>1</th><td>duration: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>2</th><td>protocol_type: symbolic.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>3</th><td>service: symbolic.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>4</th><td>flag: symbolic.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>5</th><td>src_bytes: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>6</th><td>dst_bytes: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>7</th><td>land: symbolic.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>8</th><td>wrong_fragment: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>9</th><td>urgent: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>10</th><td>hot: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>11</th><td>num_failed_logins: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>12</th><td>logged_in: symbolic.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>13</th><td>num_compromised: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>14</th><td>root_shell: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>15</th><td>su_attempted: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>16</th><td>num_root: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>17</th><td>num_file_creations: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>18</th><td>num_shells: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>19</th><td>num_access_files: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>20</th><td>num_outbound_cmds: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>21</th><td>is_host_login: symbolic.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>22</th><td>is_guest_login: symbolic.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>23</th><td>count: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>24</th><td>srv_count: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>25</th><td>serror_rate: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>26</th><td>srv_serror_rate: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>27</th><td>rerror_rate: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>28</th><td>srv_rerror_rate: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>29</th><td>same_srv_rate: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>30</th><td>diff_srv_rate: continuous.</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& back & buffer\\_overflow & ftp\\_write & guess\\_passwd & imap & \\\\\n",
       "\t\\hline\n",
       "\t& String & Missing & Missing & Missing & Missing & \\\\\n",
       "\t\\hline\n",
       "\t1 & duration: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t2 & protocol\\_type: symbolic. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t3 & service: symbolic. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t4 & flag: symbolic. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t5 & src\\_bytes: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t6 & dst\\_bytes: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t7 & land: symbolic. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t8 & wrong\\_fragment: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t9 & urgent: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t10 & hot: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t11 & num\\_failed\\_logins: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t12 & logged\\_in: symbolic. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t13 & num\\_compromised: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t14 & root\\_shell: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t15 & su\\_attempted: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t16 & num\\_root: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t17 & num\\_file\\_creations: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t18 & num\\_shells: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t19 & num\\_access\\_files: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t20 & num\\_outbound\\_cmds: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t21 & is\\_host\\_login: symbolic. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t22 & is\\_guest\\_login: symbolic. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t23 & count: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t24 & srv\\_count: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t25 & serror\\_rate: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t26 & srv\\_serror\\_rate: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t27 & rerror\\_rate: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t28 & srv\\_rerror\\_rate: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t29 & same\\_srv\\_rate: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t30 & diff\\_srv\\_rate: continuous. & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m41×23 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m back                              \u001b[0m\u001b[1m buffer_overflow \u001b[0m\u001b[1m ftp_write \u001b[0m\u001b[1m guess_pa\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String                            \u001b[0m\u001b[90m Missing         \u001b[0m\u001b[90m Missing   \u001b[0m\u001b[90m Missing \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ duration: continuous.             \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m ⋯\n",
       "   2 │ protocol_type: symbolic.          \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "   3 │ service: symbolic.                \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "   4 │ flag: symbolic.                   \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "   5 │ src_bytes: continuous.            \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m ⋯\n",
       "   6 │ dst_bytes: continuous.            \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "   7 │ land: symbolic.                   \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "   8 │ wrong_fragment: continuous.       \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "   9 │ urgent: continuous.               \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m ⋯\n",
       "  10 │ hot: continuous.                  \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  11 │ num_failed_logins: continuous.    \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  ⋮  │                 ⋮                         ⋮             ⋮           ⋮   ⋱\n",
       "  32 │ dst_host_count: continuous.       \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  33 │ dst_host_srv_count: continuous.   \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m ⋯\n",
       "  34 │ dst_host_same_srv_rate: continuo… \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  35 │ dst_host_diff_srv_rate: continuo… \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  36 │ dst_host_same_src_port_rate: con… \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  37 │ dst_host_srv_diff_host_rate: con… \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m ⋯\n",
       "  38 │ dst_host_serror_rate: continuous. \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  39 │ dst_host_srv_serror_rate: contin… \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  40 │ dst_host_rerror_rate: continuous. \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m\n",
       "  41 │ dst_host_srv_rerror_rate: contin… \u001b[90m        missing  \u001b[0m\u001b[90m  missing  \u001b[0m\u001b[90m     miss\u001b[0m ⋯\n",
       "\u001b[36m                                                  20 columns and 20 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtK = CSV.read(\"kddcup.data_10_percent_corrected\", DataFrame, header=0)\n",
    "\n",
    "#label vector will come from names\n",
    "dtNames = CSV.read(\"kddcup.names\", DataFrame, header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning KDD Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494021-element PooledArrays.PooledArray{String,UInt32,1,Array{UInt32,1}}:\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " ⋮\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\"\n",
       " \"normal.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = Array(dtNames[:,1])\n",
    "\n",
    "#clean titles for columns (pretty dataframe)\n",
    "for i in 1:size(cols,1)\n",
    "    cols[i]=replace(cols[i],\": continuous.\"=>\"\")\n",
    "    cols[i]=replace(cols[i],\": symbolic.\"=>\"\")\n",
    "    #print(cols[i,:])\n",
    "end\n",
    "\n",
    "#add target column (label we are predicting)\n",
    "push!(cols,\"target\")\n",
    "\n",
    "#set column titles to cols\n",
    "rename!(dtK,cols)\n",
    "\n",
    "dtK[:,\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for KDD ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in 1:size(dtK,2)\n",
    "#     println(i)\n",
    "#     println\n",
    "#     println(describe(dtK[:,i]))\n",
    "# end\n",
    "\n",
    "X = dtK[:,1:41]\n",
    "#binary classification, attack or not attack (if normal, not attack, if not, attack)\n",
    "#0: not an attack (normal)\n",
    "#1: attack (not normal)\n",
    "y = Vector{Int64}()\n",
    "\n",
    "#turn into binary classifciation, attack or not attack\n",
    "for i in 1:size(dtK,1)\n",
    "    if dtK[i,42] == \"normal.\"\n",
    "        push!(y,0)\n",
    "    else\n",
    "        push!(y,1)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494021-element Array{Int64,1}:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " ⋮\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# want to label encode features 2,3,4\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#print(y)\n",
    "# for i in 1:size(X,1)\n",
    "#     print(typeof(X[i,2]))\n",
    "# end\n",
    "X[!,2] = le.fit_transform(X[!,2])\n",
    "X[!,3] = le.fit_transform(X[!,3])\n",
    "X[!,4] = le.fit_transform(X[!,4])\n",
    "\n",
    "#enc = OneHotEncoder(categories=[\"sex\"],sparse=false)\n",
    "#OHE crashes computer \n",
    "X = Array(X)\n",
    "y = Array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDD Train Test Split ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Array,1}:\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 1.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0]\n",
       " [0.0 2.0 … 0.0 0.0; 0.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0]\n",
       " [1, 1, 1, 0, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n",
       " [0, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 0, 0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ScikitLearn.CrossValidation: train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian NB Classifier for KDD Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.266101 seconds (35.37 k allocations: 1.882 MiB)\n",
      "Accuracy on Training Data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant GaussianNB. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798099556408937\n",
      "Accuracy on Test Data: \n",
      "0.9798659982322022\n",
      "  0.098137 seconds (25.01 k allocations: 2.474 MiB)\n",
      "Size of model: \n",
      "2005 bytes\n"
     ]
    }
   ],
   "source": [
    "@sk_import naive_bayes: GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "@time fit!(gnb, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(gnb,X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(gnb,X_test, y_test))\n",
    "\n",
    "#time to train model on test data\n",
    "@time gnb.predict(X_test)\n",
    "\n",
    "jl.dump(gnb,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier for KDD ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.324659 seconds (22 allocations: 1.125 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.9868917973245733\n",
      "Accuracy on Test Data: \n",
      "0.9865998232202258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant DecisionTreeClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0.015627 seconds (37 allocations: 1.132 MiB)\n",
      "Size of model: \n",
      "1669 bytes\n"
     ]
    }
   ],
   "source": [
    "@sk_import tree: DecisionTreeClassifier\n",
    "\n",
    "#limit depth to lower overfitting of tree (prune)\n",
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "@time fit!(dt, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(dt, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(dt, X_test, y_test))\n",
    "\n",
    "#time to train model on test data\n",
    "@time dt.predict(X_test)\n",
    "\n",
    "jl.dump(dt,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier for KDD ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14.306521 seconds (22 allocations: 1.125 KiB)\n",
      "Accuracy on Training Data: \n",
      "0.9904081384790668\n",
      "Accuracy on Test Data: \n",
      "0.9901759026226832\n",
      "  0.010161 seconds (37 allocations: 1.132 MiB)\n",
      "Size of model: \n",
      "1070 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darkr\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\r\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\r\n"
     ]
    }
   ],
   "source": [
    "@sk_import svm: LinearSVC\n",
    "\n",
    "svc = LinearSVC(max_iter=250)\n",
    "@time fit!(svc, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(svc, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(svc, X_test, y_test))\n",
    "\n",
    "#time to train model on test data\n",
    "@time svc.predict(X_test)\n",
    "\n",
    "jl.dump(svc,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classifier for KDD ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51.398093 seconds (22 allocations: 1.125 KiB)\n",
      "Accuracy on Training Data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant MLPClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973020178477447\n",
      "Accuracy on Test Data: \n",
      "0.9971998623546796\n",
      "  0.154773 seconds (37 allocations: 1.132 MiB)\n",
      "Size of model: \n",
      "143117 bytes\n"
     ]
    }
   ],
   "source": [
    "@sk_import neural_network: MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=200)\n",
    "@time fit!(clf, X_train, y_train)\n",
    "\n",
    "println(\"Accuracy on Training Data: \")\n",
    "println(score(clf, X_train, y_train))\n",
    "\n",
    "println(\"Accuracy on Test Data: \")\n",
    "println( score(clf, X_test, y_test))\n",
    "\n",
    "#time to train model on test data\n",
    "@time clf.predict(X_test)\n",
    "\n",
    "jl.dump(clf,\"model.pkl\")\n",
    "println(\"Size of model: \")\n",
    "println(filesize(\"model.pkl\"),\" bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
